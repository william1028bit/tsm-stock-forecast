{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dfd5b04-3c9d-45f1-aa0e-52f21ad6b3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved -> tsm_open_model.joblib\n",
      "Best params: {'colsample_bytree': 0.9, 'learning_rate': 0.05, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 400, 'reg_alpha': 0.1, 'reg_lambda': 3.0, 'subsample': 0.8}\n",
      "Feature cols: 112\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import ta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit, ParameterGrid\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def rmse(a, b):\n",
    "    return float(np.sqrt(mean_squared_error(a, b)))\n",
    "\n",
    "def add_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = ta.add_all_ta_features(\n",
    "        df, open=\"Open\", high=\"High\", low=\"Low\", close=\"Close\", volume=\"Volume\", fillna=True\n",
    "    )\n",
    "\n",
    "    base = pd.DataFrame(index=df.index)\n",
    "    base[\"month\"] = df[\"Date\"].dt.month\n",
    "    base[\"dayofweek\"] = df[\"Date\"].dt.dayofweek\n",
    "    base[\"return_1\"] = df[\"Close\"].pct_change(1)\n",
    "    base[\"return_5\"] = df[\"Close\"].pct_change(5)\n",
    "    base[\"return_10\"] = df[\"Close\"].pct_change(10)\n",
    "    base[\"cci\"] = ta.trend.cci(df[\"High\"], df[\"Low\"], df[\"Close\"], window=14)\n",
    "    base[\"stc\"] = df[\"Close\"].rolling(window=5).std()\n",
    "\n",
    "    for lag in [1, 2, 5]:\n",
    "        base[f\"open_lag_{lag}\"] = df[\"Open\"].shift(lag)\n",
    "        base[f\"close_lag_{lag}\"] = df[\"Close\"].shift(lag)\n",
    "        base[f\"vol_lag_{lag}\"] = df[\"Volume\"].shift(lag)\n",
    "\n",
    "    for w in [5, 20]:\n",
    "        base[f\"close_ma_{w}\"] = df[\"Close\"].rolling(w).mean()\n",
    "        base[f\"close_std_{w}\"] = df[\"Close\"].rolling(w).std()\n",
    "\n",
    "    df = pd.concat([df, base], axis=1).copy()\n",
    "    return df\n",
    "\n",
    "def train_model(ticker=\"TSM\", start=\"2015-01-01\"):\n",
    "    df = yf.download(ticker, start=start, auto_adjust=False)\n",
    "    df.columns = df.columns.get_level_values(0)\n",
    "    df = df.reset_index()\n",
    "\n",
    "    df = add_features(df)\n",
    "\n",
    "    # target: next-day open log-return\n",
    "    df[\"target\"] = np.log(df[\"Open\"].shift(-1)) - np.log(df[\"Open\"])\n",
    "    df = df.dropna().copy()\n",
    "\n",
    "    feature_cols = [c for c in df.columns if c not in [\"Date\", \"target\"]]\n",
    "    X = df[feature_cols]\n",
    "    y = df[\"target\"]\n",
    "\n",
    "    # 24 fits small grid (same as you used)\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [400, 800],\n",
    "        \"max_depth\": [3, 4],\n",
    "        \"learning_rate\": [0.05],\n",
    "        \"subsample\": [0.8],\n",
    "        \"colsample_bytree\": [0.9],\n",
    "        \"min_child_weight\": [3],\n",
    "        \"reg_lambda\": [3.0],\n",
    "        \"reg_alpha\": [0.0, 0.1],\n",
    "    }\n",
    "\n",
    "    best_params = None\n",
    "    best_score = float(\"inf\")\n",
    "\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        scores = []\n",
    "        for tr_idx, va_idx in tscv.split(X):\n",
    "            X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "            y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "\n",
    "            model = XGBRegressor(\n",
    "                objective=\"reg:squarederror\",\n",
    "                random_state=42,\n",
    "                tree_method=\"hist\",\n",
    "                n_jobs=-1,\n",
    "                **params\n",
    "            )\n",
    "            model.fit(X_tr, y_tr, eval_set=[(X_va, y_va)], verbose=False)\n",
    "            pred = model.predict(X_va)\n",
    "            scores.append(rmse(y_va, pred))\n",
    "\n",
    "        score = float(np.mean(scores))\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_params = params\n",
    "\n",
    "    final_model = XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        random_state=42,\n",
    "        tree_method=\"hist\",\n",
    "        n_jobs=-1,\n",
    "        **best_params\n",
    "    )\n",
    "    final_model.fit(X, y, verbose=False)\n",
    "\n",
    "    bundle = {\n",
    "        \"ticker\": ticker,\n",
    "        \"start\": start,\n",
    "        \"model\": final_model,\n",
    "        \"feature_cols\": feature_cols,\n",
    "        \"best_params\": best_params,\n",
    "    }\n",
    "    return bundle\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    bundle = train_model(\"TSM\", \"2015-01-01\")\n",
    "    joblib.dump(bundle, \"tsm_open_model.joblib\")\n",
    "    print(\"Saved -> tsm_open_model.joblib\")\n",
    "    print(\"Best params:\", bundle[\"best_params\"])\n",
    "    print(\"Feature cols:\", len(bundle[\"feature_cols\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b74f50-1cd9-4efd-9b65-6e998fca385f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
